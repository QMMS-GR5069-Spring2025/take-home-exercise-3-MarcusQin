{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d721a4ef-5048-4317-874e-24d64a739e9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/09 22:05:35 INFO mlflow.tracking.fluent: Experiment with name 'f1_experiment_hw4' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not set experiment. Continuing...\n INVALID_PARAMETER_VALUE: Got an invalid experiment name 'f1_experiment_hw4'. An experiment name must be an absolute path within the Databricks workspace, e.g. '/Users/<some-username>/my-experiment'.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>raceId</th><th>driverId</th><th>resultId</th><th>constructorId</th><th>number</th><th>grid</th><th>position</th><th>positionText</th><th>positionOrder</th><th>points</th><th>laps</th><th>time</th><th>milliseconds</th><th>fastestLap</th><th>rank</th><th>fastestLapTime</th><th>fastestLapSpeed</th><th>statusId</th><th>driverRef</th><th>number</th><th>code</th><th>forename</th><th>surname</th><th>dob</th><th>nationality</th><th>url</th><th>year</th><th>round</th><th>circuitId</th><th>name</th><th>date</th><th>time</th><th>url</th><th>fp1_date</th><th>fp1_time</th><th>fp2_date</th><th>fp2_time</th><th>fp3_date</th><th>fp3_time</th><th>quali_date</th><th>quali_time</th><th>sprint_date</th><th>sprint_time</th><th>podium</th></tr></thead><tbody><tr><td>18</td><td>1</td><td>1</td><td>1</td><td>22</td><td>1</td><td>1</td><td>1</td><td>1</td><td>10.0</td><td>58</td><td>1:34:50.616</td><td>5690616</td><td>39</td><td>2</td><td>1:27.452</td><td>218.300</td><td>1</td><td>hamilton</td><td>44</td><td>HAM</td><td>Lewis</td><td>Hamilton</td><td>1985-01-07</td><td>British</td><td>http://en.wikipedia.org/wiki/Lewis_Hamilton</td><td>2008</td><td>1</td><td>1</td><td>Australian Grand Prix</td><td>2008-03-16</td><td>04:30:00</td><td>http://en.wikipedia.org/wiki/2008_Australian_Grand_Prix</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>1</td></tr><tr><td>18</td><td>2</td><td>2</td><td>2</td><td>3</td><td>5</td><td>2</td><td>2</td><td>2</td><td>8.0</td><td>58</td><td>+5.478</td><td>5696094</td><td>41</td><td>3</td><td>1:27.739</td><td>217.586</td><td>1</td><td>heidfeld</td><td>\\N</td><td>HEI</td><td>Nick</td><td>Heidfeld</td><td>1977-05-10</td><td>German</td><td>http://en.wikipedia.org/wiki/Nick_Heidfeld</td><td>2008</td><td>1</td><td>1</td><td>Australian Grand Prix</td><td>2008-03-16</td><td>04:30:00</td><td>http://en.wikipedia.org/wiki/2008_Australian_Grand_Prix</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>1</td></tr><tr><td>18</td><td>3</td><td>3</td><td>3</td><td>7</td><td>7</td><td>3</td><td>3</td><td>3</td><td>6.0</td><td>58</td><td>+8.163</td><td>5698779</td><td>41</td><td>5</td><td>1:28.090</td><td>216.719</td><td>1</td><td>rosberg</td><td>6</td><td>ROS</td><td>Nico</td><td>Rosberg</td><td>1985-06-27</td><td>German</td><td>http://en.wikipedia.org/wiki/Nico_Rosberg</td><td>2008</td><td>1</td><td>1</td><td>Australian Grand Prix</td><td>2008-03-16</td><td>04:30:00</td><td>http://en.wikipedia.org/wiki/2008_Australian_Grand_Prix</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>1</td></tr><tr><td>18</td><td>4</td><td>4</td><td>4</td><td>5</td><td>11</td><td>4</td><td>4</td><td>4</td><td>5.0</td><td>58</td><td>+17.181</td><td>5707797</td><td>58</td><td>7</td><td>1:28.603</td><td>215.464</td><td>1</td><td>alonso</td><td>14</td><td>ALO</td><td>Fernando</td><td>Alonso</td><td>1981-07-29</td><td>Spanish</td><td>http://en.wikipedia.org/wiki/Fernando_Alonso</td><td>2008</td><td>1</td><td>1</td><td>Australian Grand Prix</td><td>2008-03-16</td><td>04:30:00</td><td>http://en.wikipedia.org/wiki/2008_Australian_Grand_Prix</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>0</td></tr><tr><td>18</td><td>5</td><td>5</td><td>1</td><td>23</td><td>3</td><td>5</td><td>5</td><td>5</td><td>4.0</td><td>58</td><td>+18.014</td><td>5708630</td><td>43</td><td>1</td><td>1:27.418</td><td>218.385</td><td>1</td><td>kovalainen</td><td>\\N</td><td>KOV</td><td>Heikki</td><td>Kovalainen</td><td>1981-10-19</td><td>Finnish</td><td>http://en.wikipedia.org/wiki/Heikki_Kovalainen</td><td>2008</td><td>1</td><td>1</td><td>Australian Grand Prix</td><td>2008-03-16</td><td>04:30:00</td><td>http://en.wikipedia.org/wiki/2008_Australian_Grand_Prix</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>\\N</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         18,
         1,
         1,
         1,
         "22",
         1,
         "1",
         "1",
         1,
         10.0,
         58,
         "1:34:50.616",
         "5690616",
         "39",
         "2",
         "1:27.452",
         "218.300",
         1,
         "hamilton",
         "44",
         "HAM",
         "Lewis",
         "Hamilton",
         "1985-01-07",
         "British",
         "http://en.wikipedia.org/wiki/Lewis_Hamilton",
         2008,
         1,
         1,
         "Australian Grand Prix",
         "2008-03-16",
         "04:30:00",
         "http://en.wikipedia.org/wiki/2008_Australian_Grand_Prix",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         1
        ],
        [
         18,
         2,
         2,
         2,
         "3",
         5,
         "2",
         "2",
         2,
         8.0,
         58,
         "+5.478",
         "5696094",
         "41",
         "3",
         "1:27.739",
         "217.586",
         1,
         "heidfeld",
         "\\N",
         "HEI",
         "Nick",
         "Heidfeld",
         "1977-05-10",
         "German",
         "http://en.wikipedia.org/wiki/Nick_Heidfeld",
         2008,
         1,
         1,
         "Australian Grand Prix",
         "2008-03-16",
         "04:30:00",
         "http://en.wikipedia.org/wiki/2008_Australian_Grand_Prix",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         1
        ],
        [
         18,
         3,
         3,
         3,
         "7",
         7,
         "3",
         "3",
         3,
         6.0,
         58,
         "+8.163",
         "5698779",
         "41",
         "5",
         "1:28.090",
         "216.719",
         1,
         "rosberg",
         "6",
         "ROS",
         "Nico",
         "Rosberg",
         "1985-06-27",
         "German",
         "http://en.wikipedia.org/wiki/Nico_Rosberg",
         2008,
         1,
         1,
         "Australian Grand Prix",
         "2008-03-16",
         "04:30:00",
         "http://en.wikipedia.org/wiki/2008_Australian_Grand_Prix",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         1
        ],
        [
         18,
         4,
         4,
         4,
         "5",
         11,
         "4",
         "4",
         4,
         5.0,
         58,
         "+17.181",
         "5707797",
         "58",
         "7",
         "1:28.603",
         "215.464",
         1,
         "alonso",
         "14",
         "ALO",
         "Fernando",
         "Alonso",
         "1981-07-29",
         "Spanish",
         "http://en.wikipedia.org/wiki/Fernando_Alonso",
         2008,
         1,
         1,
         "Australian Grand Prix",
         "2008-03-16",
         "04:30:00",
         "http://en.wikipedia.org/wiki/2008_Australian_Grand_Prix",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         0
        ],
        [
         18,
         5,
         5,
         1,
         "23",
         3,
         "5",
         "5",
         5,
         4.0,
         58,
         "+18.014",
         "5708630",
         "43",
         "1",
         "1:27.418",
         "218.385",
         1,
         "kovalainen",
         "\\N",
         "KOV",
         "Heikki",
         "Kovalainen",
         "1981-10-19",
         "Finnish",
         "http://en.wikipedia.org/wiki/Heikki_Kovalainen",
         2008,
         1,
         1,
         "Australian Grand Prix",
         "2008-03-16",
         "04:30:00",
         "http://en.wikipedia.org/wiki/2008_Australian_Grand_Prix",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         "\\N",
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "raceId",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "driverId",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "resultId",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "constructorId",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "number",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "grid",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "position",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "positionText",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "positionOrder",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "points",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "laps",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "time",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "milliseconds",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "fastestLap",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "rank",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "fastestLapTime",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "fastestLapSpeed",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "statusId",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "driverRef",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "number",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "code",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "forename",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "surname",
         "type": "\"string\""
        },
        {
         "metadata": "{\"__detected_date_formats\":\"yyyy-M-d\"}",
         "name": "dob",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "nationality",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "url",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "year",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "round",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "circuitId",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{\"__detected_date_formats\":\"yyyy-M-d\"}",
         "name": "date",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "time",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "url",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "fp1_date",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "fp1_time",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "fp2_date",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "fp2_time",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "fp3_date",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "fp3_time",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "quali_date",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "quali_time",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "sprint_date",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "sprint_time",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "podium",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/09 22:06:11 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n2025/04/09 22:06:40 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: dbfs:/databricks/mlflow-tracking/3146744947217385/e35aaef2b86b45698cfc17980277f283/artifacts/spark_rf_model/sparkml, flavor: spark). Fall back to return ['pyspark==3.5.0']. Set logging level to DEBUG to see the full traceback. \n/databricks/python/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: RF_md=3_nt=20 | F1 Score: 0.6845 | Accuracy: 0.7806\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/09 22:07:14 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n2025/04/09 22:07:37 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: dbfs:/databricks/mlflow-tracking/3146744947217385/f5300f91e412489281ee70f92a4db54c/artifacts/spark_rf_model/sparkml, flavor: spark). Fall back to return ['pyspark==3.5.0']. Set logging level to DEBUG to see the full traceback. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: RF_md=3_nt=50 | F1 Score: 0.6845 | Accuracy: 0.7806\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/09 22:08:09 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n2025/04/09 22:08:33 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: dbfs:/databricks/mlflow-tracking/3146744947217385/74a59eadc0ad415a9100cbbd7c36eb6f/artifacts/spark_rf_model/sparkml, flavor: spark). Fall back to return ['pyspark==3.5.0']. Set logging level to DEBUG to see the full traceback. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: RF_md=3_nt=100 | F1 Score: 0.6845 | Accuracy: 0.7806\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/09 22:09:12 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n2025/04/09 22:09:36 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: dbfs:/databricks/mlflow-tracking/3146744947217385/47cdeb20eb8f4ca4a4038ccb218af97a/artifacts/spark_rf_model/sparkml, flavor: spark). Fall back to return ['pyspark==3.5.0']. Set logging level to DEBUG to see the full traceback. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: RF_md=5_nt=20 | F1 Score: 0.6845 | Accuracy: 0.7806\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/09 22:10:08 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n2025/04/09 22:10:34 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: dbfs:/databricks/mlflow-tracking/3146744947217385/9b8da25edb6b4b6d981f0b72b3a18d00/artifacts/spark_rf_model/sparkml, flavor: spark). Fall back to return ['pyspark==3.5.0']. Set logging level to DEBUG to see the full traceback. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: RF_md=5_nt=50 | F1 Score: 0.6845 | Accuracy: 0.7806\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/09 22:11:11 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n2025/04/09 22:11:35 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: dbfs:/databricks/mlflow-tracking/3146744947217385/272fb3086c654e478e32373fb78d50d2/artifacts/spark_rf_model/sparkml, flavor: spark). Fall back to return ['pyspark==3.5.0']. Set logging level to DEBUG to see the full traceback. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: RF_md=5_nt=100 | F1 Score: 0.6845 | Accuracy: 0.7806\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/09 22:12:09 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n2025/04/09 22:12:33 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: dbfs:/databricks/mlflow-tracking/3146744947217385/40879efb97ff487fa9726dc1bb7de5c3/artifacts/spark_rf_model/sparkml, flavor: spark). Fall back to return ['pyspark==3.5.0']. Set logging level to DEBUG to see the full traceback. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: RF_md=7_nt=20 | F1 Score: 0.6845 | Accuracy: 0.7806\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/09 22:13:10 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n2025/04/09 22:13:34 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: dbfs:/databricks/mlflow-tracking/3146744947217385/ecfc4791d7ae4dcbb5f420676d1e9f61/artifacts/spark_rf_model/sparkml, flavor: spark). Fall back to return ['pyspark==3.5.0']. Set logging level to DEBUG to see the full traceback. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: RF_md=7_nt=50 | F1 Score: 0.6845 | Accuracy: 0.7806\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/09 22:14:11 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n2025/04/09 22:14:36 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: dbfs:/databricks/mlflow-tracking/3146744947217385/ac01ed519f604f8e976c7474eb7c9cc9/artifacts/spark_rf_model/sparkml, flavor: spark). Fall back to return ['pyspark==3.5.0']. Set logging level to DEBUG to see the full traceback. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: RF_md=7_nt=100 | F1 Score: 0.6845 | Accuracy: 0.7806\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/09 22:15:10 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n2025/04/09 22:15:37 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: dbfs:/databricks/mlflow-tracking/3146744947217385/77ceb38eea70479b9a307b6c2f990182/artifacts/spark_rf_model/sparkml, flavor: spark). Fall back to return ['pyspark==3.5.0']. Set logging level to DEBUG to see the full traceback. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: RF_md=9_nt=20 | F1 Score: 0.6845 | Accuracy: 0.7806\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/09 22:16:13 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n2025/04/09 22:16:36 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: dbfs:/databricks/mlflow-tracking/3146744947217385/834e786e0f6c416baecc326bfd2ea46a/artifacts/spark_rf_model/sparkml, flavor: spark). Fall back to return ['pyspark==3.5.0']. Set logging level to DEBUG to see the full traceback. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: RF_md=9_nt=50 | F1 Score: 0.6845 | Accuracy: 0.7806\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/09 22:17:14 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n2025/04/09 22:17:38 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: dbfs:/databricks/mlflow-tracking/3146744947217385/a7f93b4697934722ad275e78eda5b7ca/artifacts/spark_rf_model/sparkml, flavor: spark). Fall back to return ['pyspark==3.5.0']. Set logging level to DEBUG to see the full traceback. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: RF_md=9_nt=100 | F1 Score: 0.6845 | Accuracy: 0.7806\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------\n",
    "# 1. Import Necessary Libraries\n",
    "# ----------------------------------------\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ----------------------------------------\n",
    "# 2. Set MLflow Experiment\n",
    "# ----------------------------------------\n",
    "# Use a simple experiment name to avoid resource conflicts.\n",
    "experiment_name = \"f1_experiment_hw4\"\n",
    "try:\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "except Exception as e:\n",
    "    print(\"Warning: Could not set experiment. Continuing...\\n\", e)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 3. Read Data from S3 (CSV files)\n",
    "# ----------------------------------------\n",
    "# Ensure your cluster has permission to access the S3 bucket.\n",
    "df_laptimes = spark.read.csv(\"s3://columbia-gr5069-main/raw/lap_times.csv\", header=True, inferSchema=True)\n",
    "df_drivers  = spark.read.csv(\"s3://columbia-gr5069-main/raw/drivers.csv\", header=True, inferSchema=True)\n",
    "df_pitstops = spark.read.csv(\"s3://columbia-gr5069-main/raw/pit_stops.csv\", header=True, inferSchema=True)\n",
    "df_results  = spark.read.csv(\"s3://columbia-gr5069-main/raw/results.csv\", header=True, inferSchema=True)\n",
    "df_races    = spark.read.csv(\"s3://columbia-gr5069-main/raw/races.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 4. Data Preprocessing and Joining\n",
    "# ----------------------------------------\n",
    "# Join 'results' with 'drivers' on \"driverId\" and then join with 'races' on \"raceId\"\n",
    "df_model = df_results.join(df_drivers, on=\"driverId\", how=\"inner\")\n",
    "df_model = df_model.join(df_races, on=\"raceId\", how=\"inner\")\n",
    "\n",
    "# Create a binary label \"podium\": 1 if position <= 3, 0 otherwise.\n",
    "df_model = df_model.withColumn(\"podium\", (col(\"position\") <= 3).cast(\"integer\"))\n",
    "\n",
    "# Filter out any rows with NULL labels (to prevent training errors).\n",
    "df_model = df_model.filter(col(\"podium\").isNotNull())\n",
    "\n",
    "# (Optional) Display the first few rows.\n",
    "display(df_model.limit(5))\n",
    "\n",
    "# ----------------------------------------\n",
    "# 5. Construct a Spark ML Pipeline\n",
    "# ----------------------------------------\n",
    "# Features used: \n",
    "#   - \"driverRef\": a string feature (to be indexed and one-hot encoded)\n",
    "#   - \"grid\": a numeric feature.\n",
    "#\n",
    "# a) Convert \"driverRef\" into numeric indices.\n",
    "driver_indexer = StringIndexer(inputCol=\"driverRef\", outputCol=\"driverRef_idx\", handleInvalid=\"skip\")\n",
    "# b) One-Hot Encode the indexed \"driverRef\"\n",
    "driver_encoder = OneHotEncoder(inputCols=[\"driverRef_idx\"], outputCols=[\"driverRef_ohe\"])\n",
    "# c) Assemble \"driverRef_ohe\" and the numeric \"grid\" into one feature vector.\n",
    "assembler = VectorAssembler(inputCols=[\"driverRef_ohe\", \"grid\"], outputCol=\"features\")\n",
    "# d) Create a RandomForestClassifier to predict the binary \"podium\" label.\n",
    "rf = RandomForestClassifier(\n",
    "    labelCol=\"podium\",\n",
    "    featuresCol=\"features\",\n",
    "    maxDepth=5,    # initial value; will be tuned\n",
    "    numTrees=50    # initial value; will be tuned\n",
    ")\n",
    "\n",
    "# Build the pipeline.\n",
    "pipeline = Pipeline(stages=[driver_indexer, driver_encoder, assembler, rf])\n",
    "\n",
    "# ----------------------------------------\n",
    "# 6. Split the Data into Train and Test Sets\n",
    "# ----------------------------------------\n",
    "train_df, test_df = df_model.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 7. MLflow Experiment: Hyperparameter Tuning and Logging\n",
    "# ----------------------------------------\n",
    "# Define evaluators for F1 score and Accuracy.\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"podium\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"podium\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "# Define hyperparameter grids:\n",
    "# Use 4 different values for maxDepth and 3 for numTrees to yield 12 runs (>= 10 experiments).\n",
    "maxDepth_values = [3, 5, 7, 9]\n",
    "numTrees_values = [20, 50, 100]\n",
    "\n",
    "# Loop over each combination of hyperparameters.\n",
    "for maxDepth in maxDepth_values:\n",
    "    for numTrees in numTrees_values:\n",
    "        run_name = f\"RF_md={maxDepth}_nt={numTrees}\"\n",
    "        with mlflow.start_run(run_name=run_name):\n",
    "            # Update the classifier hyperparameters.\n",
    "            rf.setMaxDepth(maxDepth)\n",
    "            rf.setNumTrees(numTrees)\n",
    "            \n",
    "            # Train the model pipeline.\n",
    "            model = pipeline.fit(train_df)\n",
    "            \n",
    "            # Generate predictions on the test set.\n",
    "            predictions = model.transform(test_df)\n",
    "            \n",
    "            # Evaluate the model.\n",
    "            f1_score = f1_evaluator.evaluate(predictions)\n",
    "            accuracy_score = accuracy_evaluator.evaluate(predictions)\n",
    "            \n",
    "            # Log hyperparameters and metrics.\n",
    "            mlflow.log_param(\"maxDepth\", maxDepth)\n",
    "            mlflow.log_param(\"numTrees\", numTrees)\n",
    "            mlflow.log_metric(\"f1_score\", f1_score)\n",
    "            mlflow.log_metric(\"accuracy\", accuracy_score)\n",
    "            \n",
    "            # Log the trained Spark ML model as an artifact.\n",
    "            mlflow.spark.log_model(model, artifact_path=\"spark_rf_model\")\n",
    "            \n",
    "            # Artifact 1: Generate and log a confusion matrix plot.\n",
    "            pdf = predictions.select(\"podium\", \"prediction\").toPandas()\n",
    "            cm = pd.crosstab(pdf[\"podium\"], pdf[\"prediction\"], rownames=[\"Actual\"], colnames=[\"Predicted\"])\n",
    "            plt.figure(figsize=(5, 4))\n",
    "            sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "            plt.title(f\"Confusion Matrix (maxDepth={maxDepth}, numTrees={numTrees})\")\n",
    "            cm_plot_path = f\"confusion_matrix_md{maxDepth}_nt{numTrees}.png\"\n",
    "            plt.savefig(cm_plot_path)\n",
    "            mlflow.log_artifact(cm_plot_path)\n",
    "            plt.close()\n",
    "            \n",
    "            # Artifact 2: Log a text file containing the model's feature importances.\n",
    "            # Since our pipeline's last stage is the RandomForestClassifier, we extract its feature importances.\n",
    "            rf_model = model.stages[-1]\n",
    "            importances = rf_model.featureImportances\n",
    "            fi_text_path = f\"feature_importance_md{maxDepth}_nt{numTrees}.txt\"\n",
    "            with open(fi_text_path, \"w\") as f:\n",
    "                f.write(\"Feature Importances:\\n\")\n",
    "                f.write(str(importances))\n",
    "            mlflow.log_artifact(fi_text_path)\n",
    "            \n",
    "            print(f\"Run: {run_name} | F1 Score: {f1_score:.4f} | Accuracy: {accuracy_score:.4f}\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 8. Next Steps: Review Results and Summarize Best Run\n",
    "# ----------------------------------------\n",
    "# After the experiments complete, go to the MLflow UI (found in the notebook sidebar under 'Experiments')\n",
    "# to review all runs. Identify the run with the best evaluation metrics (e.g., highest F1 score) and include\n",
    "# a brief explanation in your report on why that run is the best model.\n",
    "#\n",
    "# Finally, capture screenshots of:\n",
    "#   (a) The MLflow Experiment Homepage (showing a table of runs with parameters and metrics).\n",
    "#   (b) The Detailed Run Page for at least one run.\n",
    "#\n",
    "# These screenshots should be included in your GitHub Classroom submission.\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2025-04-09 18:05:20",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}